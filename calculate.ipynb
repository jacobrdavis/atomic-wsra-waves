{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate any additional variables that will be compared between WSRA and SWIFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read stored variables from `io.pynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stored_variable(variable_name: str):\n",
    "    \"\"\" Read a variable stored by another ipynb instance.\n",
    "\n",
    "    Read a variable from the current iPython InteractiveShell instance\n",
    "    using the iPython `store -r`magic command.  The variable is evaluated\n",
    "    upon return so that the variable is recognized in the development\n",
    "    environment (e.g., by Pylance in VS code).\n",
    "    \"\"\"\n",
    "    get_ipython().run_line_magic('store', '-r ' + variable_name)\n",
    "    return eval(variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'io.ipynb'\n",
    "atomic_wsra = read_stored_variable('atomic_wsra')\n",
    "atomic_swifts = read_stored_variable('atomic_swifts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_moment(energy_density, frequency=None, n=0):\n",
    "    \"\"\"\n",
    "    Compute 'nth' spectral moment\n",
    "\n",
    "    Input:\n",
    "        - energy, input array of energy densities ([n,1] arr OR [n,m] ndarr)\n",
    "        - freq, input array of angular_frequencies ([n,1] arr OR [n,m] ndarr)\n",
    "        - n, moment ([1,] int)\n",
    "\n",
    "    Output:\n",
    "        - mn, nth spectral moment ([1,] float)\n",
    "            * if energy is empty or invalid, mn is assigned a NaN\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Compute 4th spectral moment:\n",
    "        m4 = spectral_moment(energy, freq, n=4)\n",
    "    \"\"\"\n",
    "    if hasattr(energy_density, '__len__') and (not isinstance(energy_density, str)):\n",
    "        fn = frequency ** n\n",
    "        mn = np.trapz(energy_density * fn, x=frequency)  # axis=1\n",
    "    else:\n",
    "        mn = np.NaN\n",
    "    return mn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy-weighted mean direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the energy-weighted mean direction for the SWIFT buoys.  This metric should be more stable than the peak period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_weighted_mean(\n",
    "    X: np.ndarray,\n",
    "    energy_density: np.ndarray,\n",
    "    frequency: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\" Compute the energy-weighted mean of the input variable X.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): frequency-dependent variable of shape (f,n)\n",
    "        energy_density (np.ndarray): spectral energy density of shape (f,n)\n",
    "        frequency (np.ndarray): frequency vector of shape (f,n)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: energy weighted mean of X with shape (n)\n",
    "    \"\"\"\n",
    "    m0 = spectral_moment(energy_density, frequency, n=0)\n",
    "    weighted_integral = np.trapz(y=energy_density*X, x=frequency)\n",
    "    return weighted_integral / m0\n",
    "\n",
    "def direction(a1: np.ndarray, b1: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute direction from directional moments a1 and b1.\n",
    "\n",
    "    Args:\n",
    "        a1 (np.ndarray): normalized spectral directional moment (+E)\n",
    "        b1 (np.ndarray): normalized spectral directional moment (+N)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: direction in meteorological convention\n",
    "    \"\"\"\n",
    "    return (90 - np.rad2deg(np.arctan2(b1, a1))) % 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for swift_id, swift_ds in atomic_swifts.items():\n",
    "    energy = swift_ds['energy'].values.T\n",
    "    energy[np.isnan(energy)] = 0\n",
    "    frequency = swift_ds['freq'].values\n",
    "    frequency = np.outer(np.ones(energy.shape[0]), frequency)\n",
    "\n",
    "    a1_weighted = energy_weighted_mean(swift_ds['a1'].values.T, energy, frequency)\n",
    "    b1_weighted = energy_weighted_mean(swift_ds['b1'].values.T, energy, frequency)\n",
    "\n",
    "    swift_ds['mean_direction'] = ('time', direction(a1_weighted, b1_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to the peak direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.scatter(swift_ds['time'], swift_ds['mean_direction'], label='mean', s=5)\n",
    "ax.scatter(swift_ds['time'], swift_ds['sea_surface_wave_from_direction_at_variance_spectral_density_maximum'], label='peak', s=5)\n",
    "ax.set_ylim([0, 360])\n",
    "ax.set_ylabel('direction (deg)')\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean square slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the spectral mean square slope for each SWIFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_slope(energy_density: np.ndarray, frequency: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute spectral mean square slope.\n",
    "\n",
    "    Args:\n",
    "        energy_density (np.ndarray): spectral energy density of shape (f,n)\n",
    "        frequency (np.ndarray): frequency vector of shape (f,n)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: mean square slope with shape (n,)\n",
    "    \"\"\"\n",
    "    ACC_GRAV = 9.81\n",
    "    fourth_moment = spectral_moment(energy_density, frequency=frequency, n=4)\n",
    "    return (2*np.pi)**4 * fourth_moment / (ACC_GRAV**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for swift_id in atomic_swifts.keys():\n",
    "    energy = atomic_swifts[swift_id]['energy'].values.T\n",
    "    energy[np.isnan(energy)] = 0\n",
    "    frequency = atomic_swifts[swift_id]['freq'].values\n",
    "    frequency = np.outer(np.ones(energy.shape[0]), frequency)\n",
    "\n",
    "    mss = mean_square_slope(energy_density=energy, frequency=frequency)\n",
    "    atomic_swifts[swift_id]['mean_square_slope'] = ('time', mss)\n",
    "\n",
    "    ax.scatter(atomic_swifts[swift_id]['wind_speed'],\n",
    "               atomic_swifts[swift_id]['mean_square_slope'],\n",
    "               s=5)\n",
    "\n",
    "ax.set_xlabel('wind speed (m/s)')\n",
    "ax.set_ylabel('mean square slope (-)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `day` variable which represents the date rounded down to the nearest day.  This will be used to isolate ATOMIC missions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for swift_id in atomic_swifts.keys():\n",
    "    atomic_swifts[swift_id]['day'] = ('time', atomic_swifts[swift_id].time.dt.floor(\"D\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%store atomic_swifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WSRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `timestamp` variable which represents the time in numeric format.  This will be used for plotting and any interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_wsra['timestamp'] = ('time', pd.to_numeric(atomic_wsra['time'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `day` variable which represents the date rounded down to the nearest day.  This will be used to isolate ATOMIC missions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_wsra['day'] = ('time', atomic_wsra.time.dt.floor(\"D\").values)\n",
    "atomic_wsra['hour'] = ('time', atomic_wsra.time.dt.floor(\"H\").values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trajectory mask and overwrite the original data.  Use the limits specified in Pincus et al. (2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_wsra.wsra.create_trajectory_mask(altitude_limits=(500, 4000),\n",
    "                                        roll_limit=3)\n",
    "atomic_wsra = atomic_wsra.wsra.mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def great_circle_pairwise(\n",
    "    longitude_a: np.ndarray,\n",
    "    latitude_a: np.ndarray,\n",
    "    longitude_b: np.ndarray,\n",
    "    latitude_b: np.ndarray,\n",
    "    earth_radius: float = 6378.137,\n",
    "    mod_bearing: bool = True\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes the great circle distance (km) and true fore bearing (deg) between\n",
    "    pairs of observations in input arrays `longitude_a` and `longitude_b` and\n",
    "    `latitude_a` and `latitude_b`.\n",
    "\n",
    "    For two longitude and latitude pairs, the great circle distance is the\n",
    "    shortest distance between the two points along the Earth's surface. This\n",
    "    distance is calculated using the Haversine formula. The instances in\n",
    "    `longitude_a` and `latitude_a` are designated as point `a`; the instances\n",
    "    in `longitude_b` and `latitude_b` then form point `b`. The true fore\n",
    "    bearing is the bearing, measured from true north, of `b` as seen from `a`.\n",
    "\n",
    "    Note:\n",
    "        When given `latitude_a/b` and `longitude_a/b` of shape (n,), n > 1,\n",
    "        the great circle distance and fore bearing will be calculated between\n",
    "        `a` and `b` entries such that the returned arrays will be of shape\n",
    "        (n,). To compute the great circle distance and bearings between\n",
    "        adjacent coordinates of single longitude and latitude arrays (i.e.,\n",
    "        along a trajectory), use `great_circle_pathwise`.\n",
    "\n",
    "    Args:\n",
    "        longitude_a (np.array): of shape (n,) in units of decimal degrees\n",
    "        latitude (np.array): of shape (n,) in units of decimal degrees\n",
    "        earth_radius (float, optional): earth's radius in units of km. Defaults to 6378.137 km (WGS-84)\n",
    "        mod_bearing (bool, optional): return bearings modulo 360 deg. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.array, np.array]: great circle distances (in km) and true fore\n",
    "        bearings between adjacent longitude and latitude pairs; shape (n,)\n",
    "\n",
    "    Example: A trajectory along the Earth's equator.\n",
    "    ```\n",
    "    >> #TODO:\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    longitude_a_rad, latitude_a_rad = map(np.radians, [longitude_a, latitude_a])\n",
    "    longitude_b_rad, latitude_b_rad = map(np.radians, [longitude_b, latitude_b])\n",
    "\n",
    "    # Difference longitude and latitude\n",
    "    longitude_difference = longitude_b_rad - longitude_a_rad\n",
    "    latitude_difference = latitude_b_rad - latitude_a_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a_1 = np.sin(latitude_difference / 2) ** 2\n",
    "    a_2 = np.cos(latitude_a_rad)\n",
    "    a_3 = np.cos(latitude_b_rad)\n",
    "    a_4 = np.sin(longitude_difference / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a_1 + a_2 * a_3 * a_4))\n",
    "    distance_km = earth_radius * c\n",
    "\n",
    "    # True bearing\n",
    "    bearing_num = np.cos(latitude_b_rad) * np.sin(-longitude_difference)\n",
    "    bearing_den_1 = np.cos(latitude_a_rad) * np.sin(latitude_b_rad)\n",
    "    bearing_den_2 = - np.sin(latitude_a_rad) * np.cos(latitude_b_rad) * np.cos(longitude_difference)\n",
    "    bearing_deg = -np.degrees(np.arctan2(bearing_num, bearing_den_1 + bearing_den_2))\n",
    "\n",
    "    if mod_bearing:\n",
    "        bearing_deg = bearing_deg % 360\n",
    "\n",
    "    return distance_km, bearing_deg\n",
    "\n",
    "\n",
    "def colocate_with_path(\n",
    "    wsra_ds: xr.Dataset,\n",
    "    path_ds: xr.Dataset,\n",
    "    path_vars: Tuple,\n",
    "    wsra_vars: Tuple = ('time', 'latitude', 'longitude'),\n",
    "    temporal_tolerance: np.timedelta64 = np.timedelta64(30, 'm'),\n",
    "    spatial_tolerance: float = 1,  # km\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    TODO: update!\n",
    "    Match WSRA observations with gridded data (e.g., a model) using\n",
    "    linear interpolation in time and bilinear interpolation in space.\n",
    "\n",
    "    Note:\n",
    "        `path_vars` and `wsra_vars` are tuples specifying the names of the\n",
    "        coordinates and fields to interpolate. The names must be ordered as:\n",
    "        time, latitude, longitude, and field where field is the variable in\n",
    "        `path_ds` to be in colocated onto the WSRA dataset (and thus is only\n",
    "        provided only for `path_vars`).\n",
    "\n",
    "        For instance, if the gridded dataset coordinates are labeled as 'time',\n",
    "        'lat', and 'lon' and 'wind_speed' is the field to be colocated onto the\n",
    "        WSRA dataset, `path_vars` should be:\n",
    "        >>> path_vars = ('time', 'lat', 'lon', 'wind_speed)\n",
    "\n",
    "        `wsra_vars` defaults to the standard dataset names, though these should\n",
    "        be provided if the defaults have been modified.\n",
    "\n",
    "        Out-of-bound points are replaced by NaNs.\n",
    "\n",
    "    Args:\n",
    "        wsra_ds (xr.Dataset): WSRA observations\n",
    "        path_ds (xr.Dataset): gridded data with a field variable to be\n",
    "            interpolated onto the WSRA observations\n",
    "        temporal_tolerance (np.timedelta64, optional): max allowable time delta\n",
    "            between model and grid times. Defaults to np.timedelta64(30, 'm').\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: field variable values interpolated onto the WSRA time and\n",
    "            spatial coordinates.\n",
    "    TODO: update!\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    wsra_time = wsra_ds[wsra_vars[0]].values\n",
    "    wsra_latitude = wsra_ds[wsra_vars[1]].values\n",
    "    wsra_longitude = wsra_ds[wsra_vars[2]].values\n",
    "\n",
    "    path_time = path_ds[path_vars[0]].values\n",
    "    path_latitude = path_ds[path_vars[1]].values\n",
    "    path_longitude = path_ds[path_vars[2]].values\n",
    "\n",
    "    t_sort_indices = np.searchsorted(path_time, wsra_time)\n",
    "\n",
    "    t_sort_indices[t_sort_indices >= len(path_time)] = len(path_time)-1\n",
    "\n",
    "    time_difference = np.abs(wsra_time - path_time[t_sort_indices])\n",
    "\n",
    "    in_time = time_difference < temporal_tolerance\n",
    "\n",
    "    distances, bearings = great_circle_pairwise(\n",
    "        longitude_a=wsra_longitude,\n",
    "        latitude_a=wsra_latitude,\n",
    "        longitude_b=path_longitude[t_sort_indices],\n",
    "        latitude_b=path_latitude[t_sort_indices]\n",
    "    )\n",
    "\n",
    "    in_range = distances < spatial_tolerance\n",
    "\n",
    "    matching_boolean = np.logical_and(in_time, in_range)\n",
    "\n",
    "    matching_wsra_indices = np.where(matching_boolean)[0]\n",
    "    matching_path_indices = t_sort_indices[matching_boolean]\n",
    "    matching_distances = distances[matching_boolean]\n",
    "    matching_time_differences = time_difference[matching_boolean]\n",
    "\n",
    "    return matching_wsra_indices, matching_path_indices, matching_distances, matching_time_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_dates = np.unique(atomic_wsra['day'].dropna(dim='time'))\n",
    "\n",
    "matches_dict = []\n",
    "for date in mission_dates:\n",
    "    wsra_in_mission = atomic_wsra.where(atomic_wsra['day'] == date)  #, drop=True)\n",
    "\n",
    "    for swift_id in atomic_swifts.keys():\n",
    "        match_dict = {}\n",
    "        swift_in_mission = atomic_swifts[swift_id].where(atomic_swifts[swift_id]['day'] == date)\n",
    "\n",
    "        wsra_indices, swift_indices, distance, time_difference \\\n",
    "            = colocate_with_path(\n",
    "                wsra_ds = wsra_in_mission,\n",
    "                path_ds = swift_in_mission,\n",
    "                path_vars = ('time', 'lat', 'lon', ''),\n",
    "                wsra_vars = ('time', 'latitude', 'longitude'),\n",
    "                temporal_tolerance = np.timedelta64(60, 'm'),\n",
    "                spatial_tolerance = 55,  #km\n",
    "        )\n",
    "        match_dict['date'] = date\n",
    "        match_dict['swift_id'] = swift_id\n",
    "        match_dict['wsra_indices'] = wsra_indices\n",
    "        match_dict['swift_indices'] = swift_indices\n",
    "        match_dict['distance'] = distance\n",
    "        match_dict['time_difference'] = time_difference.astype('timedelta64[s]')\n",
    "        matches_dict.append(match_dict)\n",
    "\n",
    "matches_df = (pd.DataFrame(matches_dict)\n",
    "    .dropna()\n",
    "    .set_index(['date', 'swift_id'])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%store atomic_wsra\n",
    "%store matches_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyWSRA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
